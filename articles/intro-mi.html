<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to Multiple Imputation • Amelia</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to Multiple Imputation">
<meta property="og:description" content="Amelia">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">Amelia</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.8.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/intro-mi.html">Introduction to Multiple Imputation</a>
    </li>
    <li>
      <a href="../articles/using-amelia.html">Using Amelia</a>
    </li>
    <li>
      <a href="../articles/diagnostics.html">Multiple Imputation Diagnostics</a>
    </li>
    <li>
      <a href="../articles/ameliaview.html">AmeliaView GUI Guide</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="intro-mi_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction to Multiple Imputation</h1>
            
            <h4 class="date">2021-05-26</h4>
      
      
      <div class="hidden name"><code>intro-mi.Rmd</code></div>

    </div>

    
    
<div id="sec:intro" class="section level2">
<h2 class="hasAnchor">
<a href="#sec:intro" class="anchor"></a>Introduction</h2>
<p>Missing data is a ubiquitous problem in social science data. Respondents do not answer every question, countries do not collect statistics every year, archives are incomplete, subjects drop out of panels. Most statistical analysis methods, however, assume the absence of missing data, and are only able to include observations for which every variable is measured. Amelia allows users to impute (“fill in” or rectangularize) incomplete data sets so that analyses which require complete observations can appropriately use all the information present in a dataset with missingness, and avoid the biases, inefficiencies, and incorrect uncertainty estimates that can result from dropping all partially observed observations from the analysis.</p>
<p>Amelia performs <em>multiple imputation</em>, a general-purpose approach to data with missing values. Multiple imputation has been shown to reduce bias and increase efficiency compared to listwise deletion. Furthermore, ad-hoc methods of imputation, such as mean imputation, can lead to serious biases in variances and covariances. Unfortunately, creating multiple imputations can be a burdensome process due to the technical nature of algorithms involved.  provides users with a simple way to create and implement an imputation model, generate imputed datasets, and check its fit using diagnostics.</p>
<p>The Amelia program goes several significant steps beyond the capabilities of the first version of Amelia <span class="citation">(Honaker et al., <a href="#ref-HonJosKin98" role="doc-biblioref">n.d.</a>)</span>. For one, the bootstrap-based EMB algorithm included in Amelia can impute many more variables, with many more observations, in much less time. The great simplicity and power of the EMB algorithm made it possible to write Amelia so that it virtually never crashes — which to our knowledge makes it unique among all existing multiple imputation software — and is much faster than the alternatives too. Amelia also has features to make valid and much more accurate imputations for cross-sectional, time-series, and time-series-cross-section data, and allows the incorporation of observation and data-matrix-cell level prior information. In addition to all of this, Amelia provides many diagnostic functions that help users check the validity of their imputation model. This software implements the ideas developed in <span class="citation">Honaker and King (<a href="#ref-HonKin10" role="doc-biblioref">2010</a>)</span>.</p>
</div>
<div id="sec:what" class="section level2">
<h2 class="hasAnchor">
<a href="#sec:what" class="anchor"></a>What Amelia Does</h2>
<p>Multiple imputation involves imputing <span class="math inline">\(m\)</span> values for each missing cell in your data matrix and creating <span class="math inline">\(m\)</span> “completed” data sets. Across these completed data sets, the observed values are the same, but the missing values are filled in with a distribution of imputations that reflect the uncertainty about the missing data. After imputation with Amelia’s EMB algorithm, you can apply whatever statistical method you would have used if there had been no missing values to each of the <span class="math inline">\(m\)</span> data sets, and use a simple procedure, described below, to combine the results<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. Under normal circumstances, you only need to impute once and can then analyze the <span class="math inline">\(m\)</span> imputed data sets as many times and for as many purposes as you wish. The advantage of Amelia is that it combines the comparative speed and ease-of-use of our algorithm with the power of multiple imputation, to let you focus on your substantive research questions rather than spending time developing complex application-specific models for nonresponse in each new data set. Unless the rate of missingness is very high, <span class="math inline">\(m = 5\)</span> (the program default) is probably adequate.</p>
<div id="assumptions" class="section level3">
<h3 class="hasAnchor">
<a href="#assumptions" class="anchor"></a>Assumptions</h3>
<p>The imputation model in Amelia assumes that the complete data (that is, both observed and unobserved) are multivariate normal. If we denote the <span class="math inline">\((n \times k)\)</span> dataset as <span class="math inline">\(D\)</span> (with observed part <span class="math inline">\(D^{obs}\)</span> and unobserved part <span class="math inline">\(D^{mis}\)</span>), then this assumption is</p>
<p><span class="math display">\[\begin{equation} 
D \sim \mathcal{N}_k(\mu, \Sigma), 
\end{equation}\]</span></p>
<p>which states that <span class="math inline">\(D\)</span> has a multivariate normal distribution with mean vector <span class="math inline">\(\mu\)</span> and covariance matrix <span class="math inline">\(\Sigma\)</span>. The multivariate normal distribution is often a crude approximation to the true distribution of the data, yet there is evidence that this model works as well as other, more complicated models even in the face of categorical or mixed data <span class="citation">(see Schafer <a href="#ref-Schafer97" role="doc-biblioref">1997</a>, @SchOls98)</span>. Furthermore, transformations of many types of variables can often make this normality assumption more plausible (see @ref(sec:trans) for more information on how to implement this in Amelia).</p>
<p>The essential problem of imputation is that we only observe <span class="math inline">\(D^{obs}\)</span>, not the entirety of <span class="math inline">\(D\)</span>. In order to gain traction, we need to make the usual assumption in multiple imputation that the data are <em>missing at random</em> (MAR). This assumption means that the pattern of missingness only depends on the observed data <span class="math inline">\(D^{obs}\)</span>, not the unobserved data <span class="math inline">\(D^{mis}\)</span>. Let <span class="math inline">\(M\)</span> to be the missingness matrix, with cells <span class="math inline">\(m_{ij} = 1\)</span> if <span class="math inline">\(d_{ij} \in D^{mis}\)</span> and <span class="math inline">\(m_{ij} = 0\)</span> otherwise. Put simply, <span class="math inline">\(M\)</span> is a matrix that indicates whether or not a cell is missing in the data. With this, we can define the MAR assumption as</p>
<p><span class="math display">\[
 p(M|D) = p(M|D^{obs}).
\]</span></p>
<p>Note that MAR includes the case when missing values are created randomly by, say, coin flips, but it also includes many more sophisticated missingness models. When missingness is not dependent on the data at all, we say that the data are <em>missing completely at random</em> (MCAR). Amelia requires both the multivariate normality and the MAR assumption (or the simpler special case of MCAR). Note that the MAR assumption can be made more plausible by including additional variables in the dataset <span class="math inline">\(D\)</span> in the imputation dataset than just those eventually envisioned to be used in the analysis model.</p>
</div>
<div id="algorithm" class="section level3">
<h3 class="hasAnchor">
<a href="#algorithm" class="anchor"></a>Algorithm</h3>
<p>In multiple imputation, we are concerned with the complete-data parameters, <span class="math inline">\(\theta = (\mu, \Sigma)\)</span>. When writing down a model of the data, it is clear that our observed data is actually <span class="math inline">\(D^{obs}\)</span> and <span class="math inline">\(M\)</span>, the missingness matrix. Thus, the likelihood of our observed data is <span class="math inline">\(p(D^{obs}, M|\theta)\)</span>. Using the MAR assumption, we can break this up,</p>
<p><span class="math display">\[\begin{align}
  p(D^{obs},M|\theta) = p(M|D^{obs})p(D^{obs}|\theta).
\end{align}\]</span></p>
<p>As we only care about inference on the complete data parameters, we can write the likelihood as</p>
<p><span class="math display">\[\begin{align}
  L(\theta|D^{obs}) &amp;\propto p(D^{obs}|\theta),
\end{align}\]</span></p>
<p>which we can rewrite using the law of iterated expectations as</p>
<p><span class="math display">\[\begin{align}
  p(D^{obs}|\theta) &amp;= \int p(D|\theta) dD^{mis}.
\end{align}\]</span></p>
<p>With this likelihood and a flat prior on <span class="math inline">\(\theta\)</span>, we can see that the posterior is</p>
<p><span class="math display">\[\begin{equation}
  p(\theta | D^{obs}) \propto p(D^{obs}|\theta) = \int p(D|\theta)
  dD^{mis}.
\end{equation}\]</span></p>
<p>The main computational difficulty in the analysis of incomplete data is taking draws from this posterior. The EM algorithm <span class="citation">(Dempster, Laird, and Rubin <a href="#ref-DemLaiRub77" role="doc-biblioref">1977</a>)</span> is a simple computational approach to finding the mode of the posterior. Our EMB algorithm combines the classic EM algorithm with a bootstrap approach to take draws from this posterior. For each draw, we bootstrap the data to simulate estimation uncertainty and then run the EM algorithm to find the mode of the posterior for the bootstrapped data, which gives us fundamental uncertainty too <span class="citation">(see Honaker and King <a href="#ref-HonKin10" role="doc-biblioref">2010</a> for details of the EMB algorithm)</span>.</p>
<p>Once we have draws of the posterior of the complete-data parameters, we make imputations by drawing values of <span class="math inline">\(D^{mis}\)</span> from its distribution conditional on <span class="math inline">\(D^{obs}\)</span> and the draws of <span class="math inline">\(\theta\)</span>, which is a linear regression with parameters that can be calculated directly from <span class="math inline">\(\theta\)</span>.</p>
</div>
<div id="analysis" class="section level3">
<h3 class="hasAnchor">
<a href="#analysis" class="anchor"></a>Analysis</h3>
<p>In order to combine the results across <span class="math inline">\(m\)</span> data sets, first decide on the quantity of interest to compute, such as a univariate mean, regression coefficient, predicted probability, or first difference. Then, the easiest way is to draw <span class="math inline">\(1/m\)</span> simulations of <span class="math inline">\(q\)</span> from each of the <span class="math inline">\(m\)</span> data sets, combine them into one set of <span class="math inline">\(m\)</span> simulations, and then to use the standard simulation-based methods of interpretation common for single data sets <span class="citation">King, Tomz, and Wittenberg (<a href="#ref-KinTomWit00" role="doc-biblioref">2000</a>)</span>.</p>
<p>Alternatively, you can combine directly and use as the multiple imputation estimate of this parameter, <span class="math inline">\(\bar{q}\)</span>, the average of the <span class="math inline">\(m\)</span> separate estimates, <span class="math inline">\(q_j\)</span> <span class="math inline">\((j=1,\dots,m)\)</span>:</p>
<p><span class="math display">\[\begin{equation}
  \bar{q}=\frac{1}{m}\sum^{m}_{j=1}q_j.
\end{equation}\]</span></p>
<p>The variance of the point estimate is the average of the estimated variances from <em>within</em> each completed data set, plus the sample variance in the point estimates <em>across</em> the data sets (multiplied by a factor that corrects for the bias because <span class="math inline">\(m&lt;\infty\)</span>). Let <span class="math inline">\(SE(q_j)^2\)</span> denote the estimated variance (squared standard error) of <span class="math inline">\(q_j\)</span> from the data set <span class="math inline">\(j\)</span>, and <span class="math inline">\(S^{2}_{q}=\Sigma^{m}_{j=1}(q_j-\bar{q})^2/(m-1)\)</span> be the sample variance across the <span class="math inline">\(m\)</span> point estimates. The standard error of the multiple imputation point estimate is the square root of</p>
<p><span class="math display">\[\begin{equation}
SE(q)^2=\frac{1}{m}\sum^{m}_{j=1}SE(q_j)^2+S^2_q(1+1/m).
\end{equation}\]</span></p>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-DemLaiRub77">
<p>Dempster, Arthur P., N. M. Laird, and D. B. Rubin. 1977. “Maximum Likelihood Estimation from Incomplete Data via the Em Algorithm.” <em>Journal of the Royal Statistical Society B</em> 39: 1–38.</p>
</div>
<div id="ref-HonJosKin98">
<p>Honaker, James, Anne Joseph, Gary King, Kenneth Scheve, and Naunihal Singh. n.d. “AMELIA: A Program for Missing Data.”</p>
</div>
<div id="ref-HonKin10">
<p>Honaker, James, and Gary King. 2010. “What to Do About Missing Values in Time Series Cross-Section Data.” <em>American Journal of Political Science</em> 54 (2): 561–81.</p>
</div>
<div id="ref-KinTomWit00">
<p>King, Gary, Michael Tomz, and Jason Wittenberg. 2000. “Making the Most of Statistical Analyses: Improving Interpretation and Presentation.” <em>American Journal of Political Science</em> 44 (2): 341–55.</p>
</div>
<div id="ref-Schafer97">
<p>Schafer, Joseph L. 1997. <em>Analysis of Incomplete Multivariate Data</em>. London: Chapman &amp; Hall.</p>
</div>
<div id="ref-SchOls98">
<p>Schafer, Joseph L., and Maren K. Olsen. 1998. “Multiple Imputation for Multivariate Missing-Data Problems: A Data Analyst’s Perspective.” <em>Multivariate Behavioral Research</em> 33 (4): 545–71.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>You can combine the results automatically by doing your data analyses within <a href="https://zeligproject.org">Zelig for R</a>, or within <a href="https://gking.harvard.edu/clarify">Clarify for Stata</a>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by <a href="https://hona.kr">James Honaker</a>, <a href="https://gking.harvard.edu">Gary King</a>, <a href="https://www.mattblackwell.org">Matthew Blackwell</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
